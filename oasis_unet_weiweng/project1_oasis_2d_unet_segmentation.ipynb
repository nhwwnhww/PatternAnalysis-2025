{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "226bec76",
      "metadata": {
        "id": "226bec76"
      },
      "source": [
        "# Environment Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c5f15fdb",
      "metadata": {
        "id": "c5f15fdb",
        "outputId": "cc206740-2219-45d5-8cc6-ac5ba2bfeca4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch: 2.8.0+cu126\n",
            "torch.version.cuda: 12.6\n",
            "cuda.is_available: True\n",
            "device_count: 1\n",
            "device 0: Tesla T4 capability: (7, 5)\n",
            "\n",
            "=== nvidia-smi ===\n",
            " Fri Oct 17 09:20:12 2025       \n",
            "python: /usr/bin/python3\n",
            "platform: Linux-6.6.105+-x86_64-with-glibc2.35\n"
          ]
        }
      ],
      "source": [
        "import torch, sys, platform, subprocess, os\n",
        "\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"torch.version.cuda:\", torch.version.cuda)\n",
        "print(\"cuda.is_available:\", torch.cuda.is_available())\n",
        "print(\"device_count:\", torch.cuda.device_count())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"device 0:\", torch.cuda.get_device_name(0),\n",
        "          \"capability:\", torch.cuda.get_device_capability(0))\n",
        "try:\n",
        "    out = subprocess.check_output(\"nvidia-smi\", shell=True).decode().splitlines()[0]\n",
        "    print(\"\\n=== nvidia-smi ===\\n\", out)\n",
        "except Exception as e:\n",
        "    print(\"nvidia-smi not found / driver not working:\", e)\n",
        "print(\"python:\", sys.executable)\n",
        "print(\"platform:\", platform.platform())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "322dbde0",
      "metadata": {
        "id": "322dbde0"
      },
      "source": [
        "# init Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2337165e",
      "metadata": {
        "id": "2337165e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms.functional as TF\n",
        "from torch.cuda.amp import autocast, GradScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5ba03179",
      "metadata": {
        "id": "5ba03179"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "NUM_CLASSES = 4  # 背景 + 3 种脑组织\n",
        "IMG_SIZE = 128\n",
        "\n",
        "class OASIS2DPNGDataset(Dataset):\n",
        "    \"\"\"OASIS PNG 2D Brain Slice Dataset for segmentation\"\"\"\n",
        "    def __init__(self, image_dir, mask_dir, img_size=IMG_SIZE, augment=False):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.image_files = sorted(os.listdir(image_dir))\n",
        "        self.mask_files = sorted(os.listdir(mask_dir))\n",
        "        self.img_size = img_size\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
        "        mask_path = os.path.join(self.mask_dir, self.mask_files[idx])\n",
        "\n",
        "        # Load images\n",
        "        img = Image.open(img_path).convert(\"L\")\n",
        "        mask = Image.open(mask_path).convert(\"L\")\n",
        "\n",
        "        # Resize\n",
        "        img = TF.resize(img, [self.img_size, self.img_size])\n",
        "        mask = TF.resize(mask, [self.img_size, self.img_size], interpolation=TF.InterpolationMode.NEAREST)\n",
        "\n",
        "        # To tensor\n",
        "        img = TF.to_tensor(img)  # [1, H, W], float32\n",
        "        mask = np.array(mask, dtype=np.uint8)\n",
        "\n",
        "        # Map mask pixel values to [0, NUM_CLASSES-1]\n",
        "        mask = mask // (256 // NUM_CLASSES)\n",
        "        mask = torch.tensor(mask, dtype=torch.long)  # [H, W]\n",
        "\n",
        "        # Data augmentation\n",
        "        if self.augment:\n",
        "            if random.random() < 0.5:\n",
        "                img = TF.hflip(img); mask = TF.hflip(mask)\n",
        "            if random.random() < 0.5:\n",
        "                img = TF.vflip(img); mask = TF.vflip(mask)\n",
        "\n",
        "        return img, mask"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feb3f835",
      "metadata": {
        "id": "feb3f835"
      },
      "source": [
        "# Create Dataset (DataLoader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "ROOT = \"/content/drive/MyDrive/COMP3710/OASIS\""
      ],
      "metadata": {
        "id": "CNXUA4FadON4",
        "outputId": "f743c6e7-a664-4c00-e488-a2c5e98c2f5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "CNXUA4FadON4",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# base_path = r\"C:\\COMP3710\\OASIS\"\n",
        "base_path = ROOT\n",
        "IMG_SIZE = 128\n",
        "NUM_CLASSES = 4"
      ],
      "metadata": {
        "id": "olrZ37m9d6jS"
      },
      "id": "olrZ37m9d6jS",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "31712511",
      "metadata": {
        "id": "31712511",
        "outputId": "dca4ae81-661e-4083-a174-c670000946cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train/Val/Test samples: 9664/1120/544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "train_dataset = OASIS2DPNGDataset(\n",
        "    os.path.join(base_path, \"keras_png_slices_train\"),\n",
        "    os.path.join(base_path, \"keras_png_slices_seg_train\"),\n",
        "    img_size=IMG_SIZE,\n",
        "    augment=True\n",
        ")\n",
        "val_dataset = OASIS2DPNGDataset(\n",
        "    os.path.join(base_path, \"keras_png_slices_validate\"),\n",
        "    os.path.join(base_path, \"keras_png_slices_seg_validate\"),\n",
        "    img_size=IMG_SIZE,\n",
        "    augment=False\n",
        ")\n",
        "test_dataset = OASIS2DPNGDataset(\n",
        "    os.path.join(base_path, \"keras_png_slices_test\"),\n",
        "    os.path.join(base_path, \"keras_png_slices_seg_test\"),\n",
        "    img_size=IMG_SIZE,\n",
        "    augment=False\n",
        ")\n",
        "if __name__ == \"__main__\":\n",
        "    # train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4, pin_memory=True)\n",
        "    # train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "    train_loader = DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size=8,                # 保持合适 batch size\n",
        "      shuffle=True,\n",
        "      num_workers=4,               # 提高加载速度\n",
        "      pin_memory=True,             # 加速 CPU→GPU 传输\n",
        "    )\n",
        "    val_loader   = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "    test_loader  = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "    print(f\"Train/Val/Test samples: {len(train_dataset)}/{len(val_dataset)}/{len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "132bc36b",
      "metadata": {
        "id": "132bc36b"
      },
      "source": [
        "# Model (UNet2D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "07dad272",
      "metadata": {
        "id": "07dad272",
        "outputId": "7b0ed423-9b50-4bc2-c3b1-10463b1e3308",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model params (M): 7.849124\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "class UNet2D(nn.Module):\n",
        "    def __init__(self, in_c=1, n_classes=4, base=32, act_layer=nn.SiLU):\n",
        "        super().__init__()\n",
        "        def double_conv(ic, oc):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(ic, oc, 3, padding=1, bias=False),\n",
        "                nn.BatchNorm2d(oc),\n",
        "                act_layer(),\n",
        "                nn.Conv2d(oc, oc, 3, padding=1, bias=False),\n",
        "                nn.BatchNorm2d(oc),\n",
        "                act_layer(),\n",
        "            )\n",
        "        self.inc   = double_conv(in_c, base)\n",
        "        self.down1 = nn.Sequential(nn.MaxPool2d(2), double_conv(base, base*2))\n",
        "        self.down2 = nn.Sequential(nn.MaxPool2d(2), double_conv(base*2, base*4))\n",
        "        self.down3 = nn.Sequential(nn.MaxPool2d(2), double_conv(base*4, base*8))\n",
        "        self.bot   = nn.Sequential(nn.MaxPool2d(2), double_conv(base*8, base*16))\n",
        "        self.up1   = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        self.c1    = double_conv(base*16 + base*8, base*8)\n",
        "        self.up2   = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        self.c2    = double_conv(base*8 + base*4, base*4)\n",
        "        self.up3   = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        self.c3    = double_conv(base*4 + base*2, base*2)\n",
        "        self.up4   = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        self.c4    = double_conv(base*2 + base, base)\n",
        "        self.outc  = nn.Conv2d(base, n_classes, 1)\n",
        "\n",
        "    def _cat(self, up, skip):\n",
        "        diffY = skip.size(2) - up.size(2)\n",
        "        diffX = skip.size(3) - up.size(3)\n",
        "        up = F.pad(up, [diffX//2, diffX - diffX//2, diffY//2, diffY - diffY//2])\n",
        "        return torch.cat([skip, up], dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.bot(x4)\n",
        "        x = self.c1(self._cat(self.up1(x5), x4))\n",
        "        x = self.c2(self._cat(self.up2(x), x3))\n",
        "        x = self.c3(self._cat(self.up3(x), x2))\n",
        "        x = self.c4(self._cat(self.up4(x), x1))\n",
        "        return self.outc(x)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = UNet2D(in_c=1, n_classes=NUM_CLASSES).to(device)\n",
        "print(\"Model params (M):\", sum(p.numel() for p in model.parameters())/1e6)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93b3f853",
      "metadata": {
        "id": "93b3f853"
      },
      "source": [
        "# Loss, Optimizer, Scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1be21bd6",
      "metadata": {
        "id": "1be21bd6",
        "outputId": "8f1df3b4-7ba5-4e65-c26f-601beafc1e32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3009487755.py:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler(enabled=torch.cuda.is_available())\n"
          ]
        }
      ],
      "source": [
        "def dice_loss(logits, target, eps=1e-6):\n",
        "    probs = F.softmax(logits, dim=1)\n",
        "    tgt_1h = F.one_hot(target, probs.shape[1]).permute(0,3,1,2).float()\n",
        "    dims = (0,2,3)\n",
        "    inter = torch.sum(probs * tgt_1h, dims)\n",
        "    union = torch.sum(probs, dims) + torch.sum(tgt_1h, dims)\n",
        "    dice = (2*inter + eps) / (union + eps)\n",
        "    return 1 - dice.mean()\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-5)\n",
        "scaler = GradScaler(enabled=torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f2a4b4b",
      "metadata": {
        "id": "1f2a4b4b"
      },
      "source": [
        "# Training & Validation Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3de6500b",
      "metadata": {
        "id": "3de6500b",
        "outputId": "b4ad88bd-b4cc-46af-f669-06e94072778d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/20 [Train]:   0%|          | 0/1208 [00:00<?, ?it/s]/tmp/ipython-input-3389835909.py:13: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=torch.cuda.is_available()):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3389835909.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdice_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm  # 用于显示进度条\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    # 使用 tqdm 显示 batch 进度条\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch}/{NUM_EPOCHS} [Train]\", leave=False)\n",
        "    for imgs, masks in loop:\n",
        "        imgs, masks = imgs.to(device), masks.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with autocast(enabled=torch.cuda.is_available()):\n",
        "            logits = model(imgs)\n",
        "            loss = dice_loss(logits, masks)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        train_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "        # 实时更新 batch loss\n",
        "        loop.set_postfix({\"batch_loss\": loss.item()})\n",
        "\n",
        "    train_loss /= len(train_dataset)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss, val_dice = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, masks in val_loader:\n",
        "            imgs, masks = imgs.to(device), masks.to(device)\n",
        "            logits = model(imgs)\n",
        "            batch_loss = dice_loss(logits, masks).item()\n",
        "            val_loss += batch_loss * imgs.size(0)\n",
        "            val_dice += dice_score(logits, masks) * imgs.size(0)\n",
        "    val_loss /= len(val_dataset)\n",
        "    val_dice /= len(val_dataset)\n",
        "\n",
        "    print(f\"Epoch {epoch}/{NUM_EPOCHS} | \"\n",
        "          f\"Train Loss: {train_loss:.4f} | \"\n",
        "          f\"Val Loss: {val_loss:.4f} | \"\n",
        "          f\"Val Dice: {val_dice:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2231a588",
      "metadata": {
        "id": "2231a588"
      },
      "source": [
        "# Test & Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d7e8554",
      "metadata": {
        "id": "0d7e8554"
      },
      "outputs": [],
      "source": [
        "def visualize_predictions(model, loader, n=3):\n",
        "    model.eval()\n",
        "    imgs, masks = next(iter(loader))\n",
        "    imgs, masks = imgs.to(device), masks.to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(imgs)\n",
        "        preds = logits.argmax(dim=1)\n",
        "    imgs = imgs.cpu().numpy()\n",
        "    masks = masks.cpu().numpy()\n",
        "    preds = preds.cpu().numpy()\n",
        "\n",
        "    for i in range(min(n, imgs.shape[0])):\n",
        "        fig, axes = plt.subplots(1,3, figsize=(12,4))\n",
        "        axes[0].imshow(imgs[i,0], cmap='gray'); axes[0].set_title(\"Image\")\n",
        "        axes[1].imshow(masks[i], cmap='jet', vmin=0, vmax=NUM_CLASSES-1); axes[1].set_title(\"Mask\")\n",
        "        axes[2].imshow(preds[i], cmap='jet', vmin=0, vmax=NUM_CLASSES-1); axes[2].set_title(\"Prediction\")\n",
        "        plt.show()\n",
        "\n",
        "# 可视化前 3 个测试样本\n",
        "visualize_predictions(model, test_loader, n=3)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}