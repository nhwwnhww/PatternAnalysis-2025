{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "226bec76",
   "metadata": {},
   "source": [
    "# Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f15fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, sys, platform, subprocess, os\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torch.version.cuda:\", torch.version.cuda)\n",
    "print(\"cuda.is_available:\", torch.cuda.is_available())\n",
    "print(\"device_count:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"device 0:\", torch.cuda.get_device_name(0),\n",
    "          \"capability:\", torch.cuda.get_device_capability(0))\n",
    "try:\n",
    "    out = subprocess.check_output(\"nvidia-smi\", shell=True).decode().splitlines()[0]\n",
    "    print(\"\\n=== nvidia-smi ===\\n\", out)\n",
    "except Exception as e:\n",
    "    print(\"nvidia-smi not found / driver not working:\", e)\n",
    "print(\"python:\", sys.executable)\n",
    "print(\"platform:\", platform.platform())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322dbde0",
   "metadata": {},
   "source": [
    "# init Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2337165e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba03179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "NUM_CLASSES = 4  # 背景 + 3 种脑组织\n",
    "IMG_SIZE = 128\n",
    "\n",
    "class OASIS2DPNGDataset(Dataset):\n",
    "    \"\"\"OASIS PNG 2D Brain Slice Dataset for segmentation\"\"\"\n",
    "    def __init__(self, image_dir, mask_dir, img_size=IMG_SIZE, augment=False):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.image_files = sorted(os.listdir(image_dir))\n",
    "        self.mask_files = sorted(os.listdir(mask_dir))\n",
    "        self.img_size = img_size\n",
    "        self.augment = augment\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.mask_files[idx])\n",
    "        \n",
    "        # Load images\n",
    "        img = Image.open(img_path).convert(\"L\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "        \n",
    "        # Resize\n",
    "        img = TF.resize(img, [self.img_size, self.img_size])\n",
    "        mask = TF.resize(mask, [self.img_size, self.img_size], interpolation=TF.InterpolationMode.NEAREST)\n",
    "        \n",
    "        # To tensor\n",
    "        img = TF.to_tensor(img)  # [1, H, W], float32\n",
    "        mask = np.array(mask, dtype=np.uint8)\n",
    "        \n",
    "        # Map mask pixel values to [0, NUM_CLASSES-1]\n",
    "        mask = mask // (256 // NUM_CLASSES)\n",
    "        mask = torch.tensor(mask, dtype=torch.long)  # [H, W]\n",
    "        \n",
    "        # Data augmentation\n",
    "        if self.augment:\n",
    "            if random.random() < 0.5:\n",
    "                img = TF.hflip(img); mask = TF.hflip(mask)\n",
    "            if random.random() < 0.5:\n",
    "                img = TF.vflip(img); mask = TF.vflip(mask)\n",
    "        \n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb3f835",
   "metadata": {},
   "source": [
    "# Create Dataset (DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31712511",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = r\"C:\\COMP3710\\OASIS\"\n",
    "IMG_SIZE = 128\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "train_dataset = OASIS2DPNGDataset(\n",
    "    os.path.join(base_path, \"keras_png_slices_train\"),\n",
    "    os.path.join(base_path, \"keras_png_slices_seg_train\"),\n",
    "    img_size=IMG_SIZE,\n",
    "    augment=True\n",
    ")\n",
    "val_dataset = OASIS2DPNGDataset(\n",
    "    os.path.join(base_path, \"keras_png_slices_validate\"),\n",
    "    os.path.join(base_path, \"keras_png_slices_seg_validate\"),\n",
    "    img_size=IMG_SIZE,\n",
    "    augment=False\n",
    ")\n",
    "test_dataset = OASIS2DPNGDataset(\n",
    "    os.path.join(base_path, \"keras_png_slices_test\"),\n",
    "    os.path.join(base_path, \"keras_png_slices_seg_test\"),\n",
    "    img_size=IMG_SIZE,\n",
    "    augment=False\n",
    ")\n",
    "if __name__ == \"__main__\":\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    # train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    val_loader   = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "    test_loader  = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "    print(f\"Train/Val/Test samples: {len(train_dataset)}/{len(val_dataset)}/{len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132bc36b",
   "metadata": {},
   "source": [
    "# Model (UNet2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dad272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class UNet2D(nn.Module):\n",
    "    def __init__(self, in_c=1, n_classes=4, base=32, act_layer=nn.SiLU):\n",
    "        super().__init__()\n",
    "        def double_conv(ic, oc):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(ic, oc, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(oc),\n",
    "                act_layer(),\n",
    "                nn.Conv2d(oc, oc, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(oc),\n",
    "                act_layer(),\n",
    "            )\n",
    "        self.inc   = double_conv(in_c, base)\n",
    "        self.down1 = nn.Sequential(nn.MaxPool2d(2), double_conv(base, base*2))\n",
    "        self.down2 = nn.Sequential(nn.MaxPool2d(2), double_conv(base*2, base*4))\n",
    "        self.down3 = nn.Sequential(nn.MaxPool2d(2), double_conv(base*4, base*8))\n",
    "        self.bot   = nn.Sequential(nn.MaxPool2d(2), double_conv(base*8, base*16))\n",
    "        self.up1   = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        self.c1    = double_conv(base*16 + base*8, base*8)\n",
    "        self.up2   = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        self.c2    = double_conv(base*8 + base*4, base*4)\n",
    "        self.up3   = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        self.c3    = double_conv(base*4 + base*2, base*2)\n",
    "        self.up4   = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        self.c4    = double_conv(base*2 + base, base)\n",
    "        self.outc  = nn.Conv2d(base, n_classes, 1)\n",
    "\n",
    "    def _cat(self, up, skip):\n",
    "        diffY = skip.size(2) - up.size(2)\n",
    "        diffX = skip.size(3) - up.size(3)\n",
    "        up = F.pad(up, [diffX//2, diffX - diffX//2, diffY//2, diffY - diffY//2])\n",
    "        return torch.cat([skip, up], dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.bot(x4)\n",
    "        x = self.c1(self._cat(self.up1(x5), x4))\n",
    "        x = self.c2(self._cat(self.up2(x), x3))\n",
    "        x = self.c3(self._cat(self.up3(x), x2))\n",
    "        x = self.c4(self._cat(self.up4(x), x1))\n",
    "        return self.outc(x)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet2D(in_c=1, n_classes=NUM_CLASSES).to(device)\n",
    "print(\"Model params (M):\", sum(p.numel() for p in model.parameters())/1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b3f853",
   "metadata": {},
   "source": [
    "# Loss, Optimizer, Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be21bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(logits, target, eps=1e-6):\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    tgt_1h = F.one_hot(target, probs.shape[1]).permute(0,3,1,2).float()\n",
    "    dims = (0,2,3)\n",
    "    inter = torch.sum(probs * tgt_1h, dims)\n",
    "    union = torch.sum(probs, dims) + torch.sum(tgt_1h, dims)\n",
    "    dice = (2*inter + eps) / (union + eps)\n",
    "    return 1 - dice.mean()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-5)\n",
    "scaler = GradScaler(enabled=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2a4b4b",
   "metadata": {},
   "source": [
    "# Training & Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de6500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # 用于显示进度条\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    # 使用 tqdm 显示 batch 进度条\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch}/{NUM_EPOCHS} [Train]\", leave=False)\n",
    "    for imgs, masks in loop:\n",
    "        imgs, masks = imgs.to(device), masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast(enabled=torch.cuda.is_available()):\n",
    "            logits = model(imgs)\n",
    "            loss = dice_loss(logits, masks)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item() * imgs.size(0)\n",
    "        \n",
    "        # 实时更新 batch loss\n",
    "        loop.set_postfix({\"batch_loss\": loss.item()})\n",
    "        \n",
    "    train_loss /= len(train_dataset)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss, val_dice = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks in val_loader:\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "            logits = model(imgs)\n",
    "            batch_loss = dice_loss(logits, masks).item()\n",
    "            val_loss += batch_loss * imgs.size(0)\n",
    "            val_dice += dice_score(logits, masks) * imgs.size(0)\n",
    "    val_loss /= len(val_dataset)\n",
    "    val_dice /= len(val_dataset)\n",
    "    \n",
    "    print(f\"Epoch {epoch}/{NUM_EPOCHS} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | \"\n",
    "          f\"Val Dice: {val_dice:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2231a588",
   "metadata": {},
   "source": [
    "# Test & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7e8554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, loader, n=3):\n",
    "    model.eval()\n",
    "    imgs, masks = next(iter(loader))\n",
    "    imgs, masks = imgs.to(device), masks.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(imgs)\n",
    "        preds = logits.argmax(dim=1)\n",
    "    imgs = imgs.cpu().numpy()\n",
    "    masks = masks.cpu().numpy()\n",
    "    preds = preds.cpu().numpy()\n",
    "    \n",
    "    for i in range(min(n, imgs.shape[0])):\n",
    "        fig, axes = plt.subplots(1,3, figsize=(12,4))\n",
    "        axes[0].imshow(imgs[i,0], cmap='gray'); axes[0].set_title(\"Image\")\n",
    "        axes[1].imshow(masks[i], cmap='jet', vmin=0, vmax=NUM_CLASSES-1); axes[1].set_title(\"Mask\")\n",
    "        axes[2].imshow(preds[i], cmap='jet', vmin=0, vmax=NUM_CLASSES-1); axes[2].set_title(\"Prediction\")\n",
    "        plt.show()\n",
    "\n",
    "# 可视化前 3 个测试样本\n",
    "visualize_predictions(model, test_loader, n=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp3710",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
